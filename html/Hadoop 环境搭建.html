<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Hadoop 环境搭建</title>

    <link rel="icon" type="image/png" href="/static/favicon.png">
    <link rel="stylesheet" href="/static/main.css">
    <link rel="stylesheet" href="/static/markdown.css">
</head>
<body>
<header>
</header>
<div class="markdown-body">
    <h1>Hadoop 环境搭建</h1>
<h4>配置免密码登录</h4>
<p>添加 hadoop 用户<br />
<code>$ sudo addgroup hadoop
$ sudo adduser --ingroup hadoop hadoop</code></p>
<p>编辑<code>/etc/sudoers</code>文件，在</p>
<pre><code>root ALL=(ALL:ALL)ALL
# 行下添加
hadoop ALL=(ALL:ALL) ALL
</code></pre>
<p>否则无法sudo<br />
然后切换用hadoop登录  </p>
<p>生成ssh密钥
<code>$ mkdir .ssh
$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</code>
测试登录
<code>$ ssh localhost</code></p>
<h4>解压和配置环境变量</h4>
<p>解压 jdk 和 hadoop<br />
<code>$ tar zxvf  jdk.tar.gz  
$ tar zxvf  hadoop.tar.gz</code>
把目录移动到<code>/opt/</code>目录下
<code>$ mv -R ./jdk1.8.0_25 /opt/
$ sudo chown -R hadoop:hadoop /opt/jdk1.8.0_25
$ mv -R ./hadoop-2.6.0 /opt/
$ sudo chown -R hadoop:hadoop /opt/hadoop-2.6.0</code>
配置环境变量 
<code>$ vim .profile</code>
```
export JAVA_HOME=/opt/jdk1.8.0_25<br />
export PATH=$JAVA_HOME/bin:$PATH<br />
export CLASSPATH=$JAVA_HOME/lib  </p>
<p>export HADOOP_INSTALL=/opt/hadoop-2.6.0<br />
export PATH=$PATH:$HADOOP_INSTALL/bin<br />
```
指定 jdk 路径  </p>
<p>修改<code>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</code> 和 <code>yarn-env.sh</code>
文件把JAVA_HOME指向JDK
<code>export JAVA_HOME=/opt/jdk1.8.0_25</code></p>
<h4>修改 hadoop 配置</h4>
<p>修改配置<code>$HADOOP_HOME/etc/hadoop/core-site.xml</code></p>
<p><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;file:/opt/hadoop-2.6.1/tmp&lt;/value&gt;
        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://0.0.0.0:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code>
修改配置<code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code></p>
<p>```
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/opt/hadoop-2.6.1/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/opt/hadoop-2.6.1/tmp/dfs/data</value>
    </property>
</configuration></p>
<p><code>如果需要修改 `mapred-site.xml` 配置</code>
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>   <br />
        <name>mapred.job.tracker</name>  <br />
        <value>localhost:9001</value>   <br />
    </property>
</configuration>
```</p>
<h4>启动</h4>
<p>格式化 HDFS 
<code>$ hadoop namenode -format 
$ hadoop datanode -format</code>
启动
<code>$ $HADOOP_HOME/sbin/start-all.sh</code>
然后输入 jps 查看进程。
<code>2053 ResourceManager
2183 NodeManager
2216 Jps
1560 NameNode
1898 SecondaryNameNode
1694 DataNode</code>
要有以上6个进程。缺少一个则配置有误。<br />
成功之后可以通过 <code>http://localhost:50070/</code> 查看 HDFS 状态。
通过 <code>http://localhost:8088/</code> 查看 job 状态。</p>
<h4>测试</h4>
<p>使用 HDFS 首先要创建用户目录
<code>$ bin/hdfs dfs -mkdir -p /user/hadoop</code>
创建并上传文件到<code>input</code>目录
<code>$ bin/hdfs dfs -mkdir input
$ bin/hdfs dfs -put etc/hadoop/*.xml input
$ bin/hdfs dfs -ls input</code>
运行
<code>$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output</code></p>
<p>查看输出结果
<code>$ bin/hdfs dfs -cat output/*</code>
Hadoop运行程序时，默认输出目录不能存在，因此再次运行需要执行如下命令删除 output文件夹:
<code>$ bin/hdfs dfs -rm -r /user/hadoop/output</code>
需要关闭的时候一定要显式的调用 <code>sbin/stop-all.sh</code></p>
</div>
<footer>
    <a href="/about.html" target="_blank" class="muted">关于我</a>
</footer>
<script src="/static/min.js"></script>
</body>
</html>
